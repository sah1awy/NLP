{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29f63dc6-44e6-4054-b530-41dbff133a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os , re\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7534b816-f29c-41a1-8bc7-a1a938f378ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review = []\n",
    "for line in open(r\"movie_data/full_train.txt\",'r',encoding='utf-8'):\n",
    "    train_review.append(line.strip())\n",
    "test_review = []\n",
    "for line in open(r\"movie_data/full_test.txt\",'r',encoding='utf-8'):\n",
    "    test_review.append(line.strip())\n",
    "\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a58ebc-1890-4732-960c-77359e9133ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_space = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "space = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "rp1 = \"\"\n",
    "rp2 = \" \"\n",
    "\n",
    "def preprocess(reviews):\n",
    "    reviews = [no_space.sub(rp1,line.lower()) for line in reviews]\n",
    "    reviews = [space.sub(rp2,line) for line in reviews]\n",
    "    return reviews\n",
    "\n",
    "train_clean = preprocess(train_review)\n",
    "test_clean = preprocess(test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7997a21c-fc61-4a17-afc1-b8608200a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "x = cv.fit_transform(train_clean)\n",
    "x_test = cv.transform(test_clean)\n",
    "x_train,x_val,y_train,y_val = train_test_split(x,target,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ace65f0e-874f-477d-abf6-d59c0475ec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8938666666666667\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression(C=0.05)\n",
    "lg.fit(x_train,y_train)\n",
    "lg_pred = lg.predict(x_val)\n",
    "print(f\"Accuracy: {accuracy_score(y_val,lg_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe414c-f0c8-4d56-8a5f-de863667c391",
   "metadata": {},
   "source": [
    "# Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c351096-f84b-4f6a-9cbb-ad2bd74a82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_sw(corpus):\n",
    "    rm = []\n",
    "    for r in corpus:\n",
    "        rm.append(\" \".join([x for x in r.split() if x not in stopwords.words(\"english\")]))\n",
    "    return rm\n",
    "\n",
    "sw_train = rm_sw(train_clean)\n",
    "sw_test = rm_sw(test_clean)\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(sw_train)\n",
    "x = cv.transform(sw_test)\n",
    "x_test = cv.transform(sw_test)\n",
    "x_train, x_val, y_train, y_val = train_test_split( x, target, train_size = 0.75)\n",
    "lr = LogisticRegression(C=0.05)\n",
    "lr.fit(x_train, y_train)\n",
    "print (\"Accuracy: %s\" \n",
    "       % (accuracy_score(y_val, lr.predict(x_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "658f066d-9731-4ff4-bc18-d71e2f5bb6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d03f83de-8b17-4938-b106-d5a8ba46f626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8776\n"
     ]
    }
   ],
   "source": [
    "def stemming(corpus):\n",
    "    return [\" \".join(stemmer.stem(x) for x in line.split()) for line in corpus]\n",
    "stemmed_train = stemming(train_clean)\n",
    "stemmed_test = stemming(test_clean)\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(stemmed_train)\n",
    "X = cv.transform(stemmed_train)\n",
    "X_test = cv.transform(stemmed_test)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75)\n",
    "lr = LogisticRegression(C=0.05)\n",
    "lr.fit(X_train, y_train)\n",
    "print (\"Accuracy: %s\" \n",
    "       % (accuracy_score(y_val, lr.predict(X_val))))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "625cbd34-61b2-4333-8cff-ca03ec3abb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81968\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(train_clean)\n",
    "X = tfidf_vectorizer.transform(train_clean)\n",
    "X_test = tfidf_vectorizer.transform(test_clean)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75)\n",
    "lr = LogisticRegression(C=0.05)\n",
    "lr.fit(X_train, y_train)\n",
    "print (\"Accuracy: %s\" \n",
    "       % accuracy_score(y_val, lr.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8385825e-9ced-4e02-9900-e12a9202e0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELmohannd\\anaconda3\\envs\\tensorflow3\\lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELmohannd\\anaconda3\\envs\\tensorflow3\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(train_clean)\n",
    "X = ngram_vectorizer.transform(train_clean)\n",
    "X_test = ngram_vectorizer.transform(test_clean)\n",
    "X_train, X_val, y_train, y_val = train_test_split( X, target, train_size = 0.75)\n",
    "svm = LinearSVC(C=1.0)\n",
    "svm.fit(X_train, y_train)\n",
    "print (\"Accuracy: %s\" \n",
    "       % accuracy_score(y_val, svm.predict(X_val)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
